{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 31 19:38:35 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.181.07   Driver Version: 418.181.07   CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 48%   69C    P2   185W / 250W |  10765MiB / 11178MiB |     24%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\r\n",
      "| 53%   66C    P2    75W / 250W |  10566MiB / 11178MiB |     12%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:83:00.0 Off |                  N/A |\r\n",
      "| 70%   86C    P2   113W / 250W |  10761MiB / 11178MiB |    100%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:84:00.0 Off |                  N/A |\r\n",
      "| 54%   80C    P2   179W / 250W |   9987MiB / 11178MiB |    100%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     31658      C   python                                     10755MiB |\r\n",
      "|    1      7909      C   .../fanlina/miniconda3/envs/c4c/bin/python  7193MiB |\r\n",
      "|    1     18521      C   /home/hutianyi/.conda/envs/cv/bin/python    3363MiB |\r\n",
      "|    2     14073      C   python                                     10751MiB |\r\n",
      "|    3     14073      C   python                                      9977MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "import string\n",
    "from os.path import join, exists\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 1\n",
    "num_workers = 1\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, origin_dir, label_dir, in_tf, out_tf):\n",
    "        self.root = root\n",
    "        self.origin_dir = origin_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.in_tf = in_tf\n",
    "        self.out_tf = out_tf\n",
    "        self.file_list = []\n",
    "        self.read_files()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        filename = self.file_list[index]\n",
    "        origin = Image.open(join(self.root, self.origin_dir, filename))\n",
    "        origin = self.in_tf(origin)\n",
    "        label = Image.open(join(self.root, self.label_dir, filename))\n",
    "        label = self.out_tf(label)\n",
    "        return tuple([filename, origin, label])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def read_files(self):\n",
    "        self.file_list=os.listdir(self.root + self.label_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root, in_tf):\n",
    "        self.root = root\n",
    "        self.in_tf = in_tf\n",
    "        self.file_list = []\n",
    "        self.read_files()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        filename = self.file_list[index]\n",
    "        origin = Image.open(join(self.root, filename))\n",
    "        origin = self.in_tf(origin)\n",
    "        return tuple([filename, origin])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def read_files(self):\n",
    "        self.file_list=os.listdir(self.root)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "class Convert(object):\n",
    "    def __init__(self, type):\n",
    "        self.type = type\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        sample = sample.convert(self.type)\n",
    "        return sample\n",
    "\n",
    "class Resize(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        new_h, new_w = int(self.output_size), int(self.output_size)\n",
    "\n",
    "        sample = sample.resize((new_h, new_w), Image.BICUBIC)\n",
    "\n",
    "        return sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_area_dataset:  979\n",
      "val_area_dataset:  100\n",
      "train_gland_dataset:  904\n",
      "val_gland_dataset:  100\n",
      "test_dataset:  347\n"
     ]
    }
   ],
   "source": [
    "input_size = 512\n",
    "output_size = 512\n",
    "\n",
    "train_area_root = 'data/eyelid/train/train_area/'\n",
    "train_gland_root = 'data/eyelid/train/train_gland/'\n",
    "val_area_root = 'data/eyelid/train/val_area/'\n",
    "val_gland_root = 'data/eyelid/train/val_gland/'\n",
    "test_root = 'data/eyelid/test/eye_image/'\n",
    "origin_dir = 'img/'\n",
    "label_dir = 'labelcol/'\n",
    "\n",
    "in_tf = transforms.Compose([\n",
    "    Convert('RGB'),\n",
    "    Resize(input_size),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "out_tf = transforms.Compose([\n",
    "    Convert('1'),\n",
    "    Resize(output_size),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_area_dataset = ImageDataset(root=train_area_root, origin_dir=origin_dir,\n",
    "                                  label_dir=label_dir, in_tf=in_tf, out_tf=out_tf)\n",
    "\n",
    "val_area_dataset = ImageDataset(root=val_area_root, origin_dir=origin_dir,\n",
    "                                  label_dir=label_dir, in_tf=in_tf, out_tf=out_tf)\n",
    "\n",
    "train_gland_dataset = ImageDataset(root=train_gland_root, origin_dir=origin_dir,\n",
    "                                  label_dir=label_dir, in_tf=in_tf, out_tf=out_tf)\n",
    "\n",
    "val_gland_dataset = ImageDataset(root=val_gland_root, origin_dir=origin_dir,\n",
    "                                  label_dir=label_dir, in_tf=in_tf, out_tf=out_tf)\n",
    "\n",
    "test_dataset = TestDataset(root=test_root, in_tf=in_tf)\n",
    "\n",
    "print('train_area_dataset: ', len(train_area_dataset))\n",
    "print('val_area_dataset: ', len(val_area_dataset))\n",
    "print('train_gland_dataset: ', len(train_gland_dataset))\n",
    "print('val_gland_dataset: ', len(val_gland_dataset))\n",
    "print('test_dataset: ', len(test_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "train_area_loader = torch.utils.data.DataLoader(\n",
    "    train_area_dataset, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "val_area_loader = torch.utils.data.DataLoader(\n",
    "    val_area_dataset, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "train_gland_loader = torch.utils.data.DataLoader(\n",
    "    train_gland_dataset, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "val_gland_loader = torch.utils.data.DataLoader(\n",
    "    val_gland_dataset, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=num_workers, pin_memory=True, drop_last=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    构造上采样模块--左边特征提取基础模块\n",
    "\"\"\"\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolution Block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(conv_block, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            # 在卷积神经网络的卷积层之后总会添加BatchNorm2d进行数据的归一化处理，这使得数据在进行Relu之前不会因为数据过大而导致网络性能的不稳定\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    构造下采样模块--右边特征融合基础模块\n",
    "\"\"\"\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    \"\"\"\n",
    "    Up Convolution Block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(up_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "\n",
    "\"\"\"\n",
    "    模型主架构\n",
    "\"\"\"\n",
    "\n",
    "class U_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet - Basic Implementation\n",
    "    Paper : https://arxiv.org/abs/1505.04597\n",
    "    \"\"\"\n",
    "\n",
    "    # 输入是3个通道的RGB图，输出是0或1——因为我的任务是2分类任务\n",
    "    def __init__(self, in_ch=3, out_ch=1):\n",
    "        super(U_Net, self).__init__()\n",
    "\n",
    "        # 卷积参数设置\n",
    "        n1 = 64\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "\n",
    "        # 最大池化层\n",
    "        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 左边特征提取卷积层\n",
    "        self.Conv1 = conv_block(in_ch, filters[0])\n",
    "        self.Conv2 = conv_block(filters[0], filters[1])\n",
    "        self.Conv3 = conv_block(filters[1], filters[2])\n",
    "        self.Conv4 = conv_block(filters[2], filters[3])\n",
    "        self.Conv5 = conv_block(filters[3], filters[4])\n",
    "\n",
    "        # 右边特征融合反卷积层\n",
    "        self.Up5 = up_conv(filters[4], filters[3])\n",
    "        self.Up_conv5 = conv_block(filters[4], filters[3])\n",
    "\n",
    "        self.Up4 = up_conv(filters[3], filters[2])\n",
    "        self.Up_conv4 = conv_block(filters[3], filters[2])\n",
    "\n",
    "        self.Up3 = up_conv(filters[2], filters[1])\n",
    "        self.Up_conv3 = conv_block(filters[2], filters[1])\n",
    "\n",
    "        self.Up2 = up_conv(filters[1], filters[0])\n",
    "        self.Up_conv2 = conv_block(filters[1], filters[0])\n",
    "\n",
    "        self.Conv = nn.Conv2d(filters[0], out_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "\t# 前向计算，输出一张与原图相同尺寸的图片矩阵\n",
    "    def forward(self, x):\n",
    "        e1 = self.Conv1(x)\n",
    "        # import os('e1.size=', e1.size())\n",
    "\n",
    "        e2 = self.Maxpool1(e1)\n",
    "        e2 = self.Conv2(e2)\n",
    "        #  ('e2.size=', e2.size())\n",
    "\n",
    "        e3 = self.Maxpool2(e2)\n",
    "        e3 = self.Conv3(e3)\n",
    "        # pid = os.getpid()('e3.size=', e3.size())\n",
    "\n",
    "        e4 = self.Maxpool3(e3)\n",
    "        e4 = self.Conv4(e4)\n",
    "        # !kill -9 $pid('e4.size=', e4.size())\n",
    "\n",
    "        e5 = self.Maxpool4(e4)\n",
    "        e5 = self.Conv5(e5)\n",
    "        # ('e5.size=', e5.size())\n",
    "\n",
    "        d5 = self.Up5(e5)\n",
    "        # ('d5.size=', d5.size())\n",
    "        d5 = torch.cat((e4, d5), dim=1)  # 将e4特征图与d5特征图横向拼接\n",
    "\n",
    "\n",
    "        d5 = self.Up_conv5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        # ('d4.size=', d4.size())\n",
    "        d4 = torch.cat((e3, d4), dim=1)  # 将e3特征图与d4特征图横向拼接\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        # ('d3.size=', d3.size())\n",
    "        d3 = torch.cat((e2, d3), dim=1)  # 将e2特征图与d3特征图横向拼接\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        # print('d2.size=', d2.size())\n",
    "        d2 = torch.cat((e1, d2), dim=1)  # 将e1特征图与d1特征图横向拼接\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        out = self.Conv(d2)\n",
    "\n",
    "        out = nn.Sigmoid()(out)\n",
    "\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded./model/unet_area_v4.pth_epoch-60!\n"
     ]
    }
   ],
   "source": [
    "from torchvision.utils import save_image\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_name = './model/unet_area_v4.pth_epoch-60'\n",
    "area_save_path = './output/area_up_and_bottom/'\n",
    "gland_save_path = './output/gland_up_and_bottom/'\n",
    "os.makedirs(area_save_path,exist_ok=True)\n",
    "os.makedirs(gland_save_path,exist_ok=True)\n",
    "net = U_Net().cuda()\n",
    "# net = U_Net()\n",
    "opt = torch.optim.Adam(net.parameters())\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "\n",
    "# 判断是否存在模型\n",
    "if os.path.exists(model_name):\n",
    "    net.load_state_dict(torch.load(model_name))\n",
    "    print(f\"Loaded{model_name}!\")\n",
    "else:\n",
    "    print(\"No Param!\")\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    y_pred = y_pred[0].flatten()\n",
    "    y_true = y_true[0].flatten()\n",
    "    y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
    "    acc = 1.0 * np.sum(y_pred == y_true) / len(y_true)\n",
    "    return acc\n",
    "\n",
    "# 训练\n",
    "def train(train_data, val_data):\n",
    "    net.cuda()\n",
    "    best_acc = 0\n",
    "    less_than = 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        losses = []\n",
    "\n",
    "        for filenames, inputs, labels in tqdm(train_data, desc=f\"Train Epoch {epoch}/{epochs}\",ncols=100):\n",
    "            # print(filenames)\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            opt.zero_grad()\n",
    "            out = net(inputs)\n",
    "            loss = loss_func(out, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            losses.append(loss.item())\n",
    "            y_pred.append(out.data.cpu().numpy())\n",
    "            y_true.append(labels.cpu().numpy())\n",
    "        Loss = np.mean(losses)\n",
    "        Acc = accuracy(y_pred, y_true)\n",
    "        print(f\"Train Loss: {round(Loss, 4)}, Acc: {round(Acc, 4)} ;\", end='')\n",
    "        test_acc = test(val_data)\n",
    "        if epoch% 10 == 0:\n",
    "            output_image(val_data, os.path.join(area_save_path, f'epoch-{epoch}'))\n",
    "            torch.save(net.state_dict(), model_name + f'_epoch-{epoch}')\n",
    "        # if test_acc > best_acc:\n",
    "        #     best_acc = test_acc\n",
    "        #     less_than = 0\n",
    "        # else:\n",
    "        #     less_than = less_than + 1\n",
    "        # if less_than > 5:\n",
    "        #     break\n",
    "\n",
    "def test(val_data):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        losses = []\n",
    "        for filenames, inputs, labels in val_data:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            out = net(inputs)\n",
    "            loss = loss_func(out, labels)\n",
    "            losses.append(loss.item())\n",
    "            y_pred.append(out.cpu().numpy())\n",
    "            y_true.append(labels.cpu().numpy())\n",
    "        Loss = np.mean(losses)\n",
    "        Acc = accuracy(y_pred, y_true)\n",
    "        print(f\"Test Loss: {round(Loss, 4)}, Acc: {round(Acc, 4)}\")\n",
    "        return Acc\n",
    "\n",
    "def pred2int(x):\n",
    "    x = x[0]\n",
    "    out = []\n",
    "    for i in range(len(x)):\n",
    "        # print(x[i])\n",
    "        out.append([1 if y > 0.5 else 0 for y in x[i].data])\n",
    "    out = torch.Tensor(out)\n",
    "    out = torch.unsqueeze(out, 0).cuda()\n",
    "    return out\n",
    "\n",
    "def output_image(data, saved_path):\n",
    "    net.eval()\n",
    "    origin_saved_path = os.path.join(saved_path, 'origin')\n",
    "    pred_saved_path = os.path.join(saved_path, 'pred')\n",
    "    label_saved_path = os.path.join(saved_path, 'label')\n",
    "\n",
    "    for path in [origin_saved_path, pred_saved_path, label_saved_path]:\n",
    "        os.makedirs(path,exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        for filenames, inputs, labels in tqdm(data, ncols=100) :\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                out = net(inputs)\n",
    "                for i in range(len(inputs)):\n",
    "                    x = inputs[i]\n",
    "                    x_ = pred2int(out[i].cpu())\n",
    "                    y = labels[i]\n",
    "                    filename = filenames[i]\n",
    "                    save_image(x.cpu(), os.path.join(origin_saved_path, filename))\n",
    "                    save_image(x_.cpu(), os.path.join(pred_saved_path, filename))\n",
    "                    save_image(y.cpu(), os.path.join(label_saved_path, filename))\n",
    "        print(\"image save successfully !\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 100/100 [03:58<00:00,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image save successfully !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_image(val_area_loader, area_save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pid = os.getpid()\n",
    "!kill -9 $pid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train(train_area_loader, val_area_loader)\n",
    "    torch.save(net.state_dict(), model_name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "UNIT_SIZE = 256 # 单个图像的大小为229*229\n",
    "TARGET_WIDTH = 3 * UNIT_SIZE # 拼接完后的横向长度为3*229\n",
    "\n",
    "path = \"./output/tube\"\n",
    "images = [] # 先存储所有的图像的名称\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for f in files :\n",
    "        images.append(f)\n",
    "for i in range(1, 101):\n",
    "    imagefile = []\n",
    "    j = 0\n",
    "    imagefile.append(Image.open(f'{path}/{str(i).rjust(4, \"0\")}_origin.png'))\n",
    "    imagefile.append(Image.open(f'{path}/{str(i).rjust(4, \"0\")}_pred.png'))\n",
    "    imagefile.append(Image.open(f'{path}/{str(i).rjust(4, \"0\")}_label.png'))\n",
    "    target = Image.new('RGB', (TARGET_WIDTH, UNIT_SIZE))\n",
    "    left = 0\n",
    "    right = UNIT_SIZE\n",
    "    for image in imagefile:\n",
    "        target.paste(image, (left, 0, right, UNIT_SIZE))# 将image复制到target的指定位置中\n",
    "        left += UNIT_SIZE # left是左上角的横坐标，依次递增\n",
    "        right += UNIT_SIZE # right是右下的横坐标，依次递增\n",
    "        quality_value = 100 # quality来指定生成图片的质量，范围是0～100\n",
    "        target.show(  )\n",
    "        target.save(f'{path}/r_{str(i).rjust(4, \"0\")}_result.png', quality = quality_value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"dark_background\")\n",
    "# random.seed(0)\n",
    "from pathlib import Path\n",
    "eps = 1.0e-6\n",
    "def test(img_dir):\n",
    "    pred_dir = os.path.join(img_dir, 'pred')\n",
    "    label_dir = os.path.join(img_dir, 'label')\n",
    "    file_list = os.listdir(pred_dir)\n",
    "    assert len(file_list) == len(os.listdir(label_dir))\n",
    "\n",
    "    print(f'Total len of test set is {len(file_list)}')\n",
    "\n",
    "    IoU, precision, recall, sensiticity, specificity, F1 = [], [], [], [], [], []\n",
    "    for file_name in tqdm(file_list, ncols=100):\n",
    "        ref_img = np.asarray(Image.open(os.path.join(label_dir, file_name)).convert('1'))\n",
    "        out_img = np.asarray(Image.open(os.path.join(pred_dir, file_name)).convert('1'))\n",
    "\n",
    "        TP = out_img & ref_img\n",
    "        TN = ~out_img & ~ref_img\n",
    "        FP = out_img & ~ref_img\n",
    "        FN = ~out_img & ref_img\n",
    "\n",
    "        TP, TN, FP, FN = [idx.sum() for idx in (TP, TN, FP, FN)]\n",
    "        IoU.append(TP / (TP + FP + FN + eps))\n",
    "        precision.append(TP / (TP + FP + eps))\n",
    "        recall.append(TP / (TP + FN + eps))\n",
    "        F1.append(2 * (TP / (TP + FP + eps)) * (TP / (TP + FN + eps)) / ((TP / (TP + FP + eps)) + (TP / (TP + FN + eps)) + eps))\n",
    "        sensiticity.append(TP / (TP + FN + eps))\n",
    "        specificity.append(TN / (TN + FP + eps))\n",
    "    print(f'IoU: {np.mean(IoU):.4%}, precision: {np.mean(precision):.4%}, recall: {np.mean(recall):.4%},\\nF1 score: {np.mean(F1):.4%}, sensiticity: {np.mean(sensiticity):.4%}, specificity: {np.mean(specificity):.4%}')\n",
    "\n",
    "print('眼睑区域')\n",
    "test(\"./output/area/\")\n",
    "print('腺管')\n",
    "test(\"./output/gland/\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pid = os.getpid()\n",
    "!kill -9 $pid\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}